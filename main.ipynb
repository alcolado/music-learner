{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import midi_tools\n",
    "import data_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "piece = './pathetique_2_format0.mid'\n",
    "n_notes = 128\n",
    "quantization = 0.05 # time quantization is seconds for reading midi file into chords\n",
    "go_time = 50 # from what time to learn the fragment\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = midi_tools.chordify(piece, quantization=quantization, num_notes=n_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sample and batch generators\n",
    "sampler = data_tools.sample_generator(data, go_time)\n",
    "batcher = data_tools.batch_generator(data, go_time, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test quantization of piece\n",
    "midi_tools.test_quantization(piece, quantization=quantization, name='quantization_test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test sample\n",
    "midi_tools.chords2midi(next(sampler), quantization=quantization, name='sample_test.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network hyperparameters \n",
    "n_1 = 128 # number of nodes in first layer \n",
    "n_2 = 128 # number of nodes in rnn cell\n",
    "depth = 2 # number of rnn cells to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build graph\n",
    "with tf.variable_scope('inputs'):\n",
    "    # shapes are [batch_size, seq_length, n_notes]\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, None, n_notes], name='x') # input sequence\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, None, n_notes], name='y') # target sequence\n",
    "\n",
    "with tf.variable_scope('network'):\n",
    "    # first layer\n",
    "    x_1 = tf.contrib.layers.fully_connected(inputs=x, num_outputs=n_1, activation_fn=None)\n",
    "\n",
    "    # rnn layers\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells=[tf.contrib.rnn.BasicLSTMCell(n_2) for _ in range(depth)])\n",
    "\n",
    "    # initial state for rnn\n",
    "    initial_state = cell.zero_state(batch_size=tf.shape(x)[0], dtype=tf.float32) # initial_state\n",
    "\n",
    "    # unroll the rnn\n",
    "    x_2, state = tf.nn.dynamic_rnn(cell, x_1, initial_state=initial_state)\n",
    "\n",
    "    # final layer\n",
    "    z = tf.contrib.layers.fully_connected(inputs=x_2, num_outputs=n_notes, activation_fn=None)\n",
    "\n",
    "with tf.variable_scope('predict'):\n",
    "    p = tf.nn.sigmoid(z, name='p')\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    # only compute loss from go_time\n",
    "    logits = z[:,go_time:,:] \n",
    "    labels = y[:,go_time:,:]\n",
    "    # loss\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels), name='loss')\n",
    "\n",
    "with tf.variable_scope('train'):\n",
    "    train = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "# start session\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "ckpt = tf.train.get_checkpoint_state('tf_checkpoints')\n",
    "\n",
    "# train\n",
    "# if checkpoint exists, restore from checkpoint\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print('model restored')\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('model initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.691269\n",
      "100 0.0793691\n",
      "200 0.0931354\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for i in range(100000):\n",
    "    batch = next(batcher)\n",
    "    l, _ = sess.run([loss, train], feed_dict={x:batch[:,:-1,:], y:batch[:,1:,:]})\n",
    "    if i % 100 == 0:\n",
    "        saver.save(sess, \"tf_checkpoints/model.ckpt\")\n",
    "        print(i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "initial_sample = next(sampler)\n",
    "initial_seq = np.reshape(initial_sample, newshape=[1,-1,n_notes])[:,:go_time+1,:]\n",
    "\n",
    "# first part of rnn\n",
    "p_val, state_val = sess.run([p, state], feed_dict={x:initial_seq})\n",
    "next_chord = np.round(p_val[0,-1,:])\n",
    "\n",
    "continued_seq = [next_chord]\n",
    "for _ in range(go_time):\n",
    "    new_input = np.reshape(next_chord, newshape=[1,1,-1])\n",
    "    p_val, state_val = sess.run([p, state], feed_dict={x:new_input, initial_state:state_val})\n",
    "    next_chord = np.round(p_val[0,-1,:])\n",
    "    continued_seq += [next_chord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midi_tools.chords2midi(initial_sample, name='initial_sample.mid')\n",
    "midi_tools.chords2midi(continued_seq, name='prediction.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
